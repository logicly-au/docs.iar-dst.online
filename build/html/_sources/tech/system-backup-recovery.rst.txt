System Backup and Recovery
===========================

Policy
-------

Comprehensive Risk Management, Disaster Recovery and Systems Recovery Plans, and Testing Timetables are to be developed, tested and maintained by the IT Section in conjunction with the ITSM. Similarly, Business Continuity Plans are to be developed, tested and maintained. All plans are to be reviewed, kept up to date and tested according to a defined continuous improvement schedule. Each plan is to be tested at least once per year.

A core component of the Disaster Recovery and Systems Recovery Plans is an online / offsite backup system.

Strategic Data is to operate an automated online backup system which performs regular scheduled backups to provide day-to-day coverage of all critical systems and services. It is to operate at both the Fitzroy office and the data center.

The backups at global center and AMHOCN are to be synchronised to the Fitzroy office backup server. Encrypted backups (using an appropriate ASD Approved Cryptographic Algorithm) for secure offsite storage are to be created from the site local replica.

Backup of all applications and systems is to be the responsibility of the IT Section. This responsibility is to include support for full forward recovery so that minimal data is lost in the event of a system failure.

All systems which are not under automated configuration management are to be included in a backup schedule. This includes Windows servers which require a configuration to be added manually at server installation. It is the responsibility of the administrator who is setting up the server to ensure that this action is effected.


Procedures
-----------

The backup system currently operates in three places:

* Servers in the Fitzroy office: hostname = backup03.mel.strategicdata.com.au

   * `http://backup.mel.strategicdata.com.au/ <http://backup.mel.strategicdata.com.au/>`_

* Servers in the data center: hostname = mel-backup01.strategicdata.internal

   * `http://backup.strategicdata.internal/ <http://backup.strategicdata.internal/>`_

All servers are backed up by servers in the same domain as per the following schedule:

* 5 x full backup at 1 week interval
* 2 x full backup at 2 week interval
* 10 x full backup at 4 week interval
* 2 x full backup at 8 week interval
* 2 x full backup at 16 week interval
* 2 x full backup at 32 week interval
* 2 x full backup at 64 week interval

Rotating full and incremental backups are performed.

All servers under configuration control are automatically added to the backup server at their respective location. The backup servers are configured to perform complete system backups with the ability to exclude non critical content.


Adding backup configurations
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

**Adding a configuration to backup puppet managed systems**

When a node is puppetted, a configuration is created automatically in the appropriate backup system.

**Adding a configuration to backup a windows server**

*BackupPC*

Check into "puppet:///modules/backuppc/files/${server_name}.pl with the following contents

 ::

	 #
	 # Local server backup of /etc as user backuppc
	 #
	 $Conf{XferMethod}       = 'smb';
	 $Conf{SmbShareName}     = ['${name of share 1 to backup}', '${name of share 2 to backup}'];
	 $Conf{SmbShareUserName} = 'STRATDAT\${user to log in as}';
	 $Conf{SmbSharePasswd}   = '${password of that user}';

Ensure you then apply this on the relevant backup server via a clause like:

 ::

   backuppc::dump { "${server_name.pl}": }

*Dirvish*

* It was decided that the data needing to be backed up be copied to fileserver using :doc:`Cobian Backup <cobian-backup>`

* whole virtual machines are also backed up :doc:`Windows Backup <windows-backup>`

Recovering Backups
^^^^^^^^^^^^^^^^^^^^

**BackupPC**

*Recovering a Full System from Online Backup*

1. partition and format the target system

   * for a virtual machine, this means "create the storage space".

   * for a physical machine, boot from a LiveCD with network, and partition and format the drives appropriately.

2. log in to the backup server and prepare the recovery stream:

   * ``sudo -u backuppc -i``

   * ``/usr/share/backuppc/bin/BackupPC_tarCreate -h ${fqdn} -n -1 -s / . | nc -l -p 3000 -q1``

3. on the target machine, execute:

   * ``cd /path/to/root/of/host (you can use the root of a guest i.e. /var/lib/vz/private/[cid number])``

   * ``nc ${backup} 3000 | tar xv --numeric-owner``

   * the netcat command on the other machine will wait until it receives a connection

Make **ABSOLUTELY CERTAIN** that the ``--numeric-owner`` switch is included otherwise there is a risk of corrupting the UID/GID assignment inside the tarfile.

Once the content has finished extracting, the system should be in a bootable state. In the event that it is not, the most likely cause is a missing component of the directory structure under ``/var``. The solution is to reinstall the package viz ``aptitude reinstall ${package}``

*Recover a directory using the CLI*

**STOP**: This command must be run as the backuppc user

 ::

   /usr/share/backuppc/bin/BackupPC_tarCreate -h ${backup server FQDN}  -n -1 -s / etc/apache2 > etc.tar

where:

* ``-s /`` is the next path is relative to this one in the backup

* ``etc/apache2`` is the directory for the tar file. (Note the lack of preceding / - defined in the command above)

* ``etc.tar`` the tar to be created

 ::

   /usr/share/backuppc/bin/BackupPC_tarCreate -h ${backup server FQDN}  -n -2 -s /usr share/backuppc > bpc.tar

where:

* ``-s /usr`` denotes the /usr share does not exist in / (ie when /usr is a separate partition)

*Recover files from backuppc ARCHIVE*

The archives of machines currently not being backed up are located in ``/var/lib/backuppc/archive``.

Where there is a requirement to recover something from one of these machines, either:

* use the command line tools, or

* add it back to the live pool.

To make a machine archive accessible:

* SSH to the relevant backup server and sudo to root

* SU to the backuppc user

* link the required archive into the machine pool, viz:

  ::

    ln -s archive/{name of archive} pc/sysrestore

* browse to the backup pc GUI and perform the following actions:

   * under server click "edit hosts" (menu on the left)

   * click the "add" button at the bottom of the page - this will create a new line

   * fill in ``sysrestore`` as the name and then copy the other two fields from the line above

   * click save - this is at the very top of the page

   * click "host summary" then select ``sysrestore``

   * click stop/dequeue backup

   * set number of hours to a large number - longer than this will exist

   * play with your backup

   * when finished

      * click on edit hosts

      * click the delete button to the left of ``sysrestore``

      * click save at the top of the page

      * as the backuppc user ``cd /var/lib/backuppc/pc; rm sysrestore``

Ensure the directory and the host entry match.

**Dirvish**

* :doc:`Dirvish Backup <dirvish-backup>`


Offsite Backup (Disaster Recovery)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Strategic Data operates an offsite backup system, intended only for disaster recovery.

It is acceptable that there is a substantial investment of effort required to use the offsite backup system to recover data, as it should only be required for testing, or for recovery when the online backup systems have been lost or compromised.

The offsite backup is an archive of the online backup server. Disaster recovery requires that the online backup server is first recovered from the archive; followed by the backed up systems.

The directors at Strategic Data have the private key associated with the offsite backup system. This key is not stored on the Strategic Data network.

Recovery of a complete offsite backup should be attempted every 6 months. An automated reminder will be sent to the sysadmin team to perform this action. If the procedure fails, an incident report must be produced for auditing purposes and a new procedure developed.

**Weekly disk collection / rotation by Iron Mountain**

Iron Mountain arrives each week between 12pm and 2pm to drop off a cycled disk and retrieve the new backup disk.

* System Administrators are emailed / SMS'd (choice is theirs) at 10am with the mount status of the backup disk and a reminder that it is Iron Mountain day

* If disc is unmounted (read notification) it should be removed and placed in box for pickup.

* After disc is replaced it needs to be reconnected

* If the disc is not connected by 4pm an SMS goes out

* cron starts creating the offsite backup late Thursday night (first thing it does is mount the disc)

**Emergency Retrieval of Backups.**

From the Iron Mountain Help Document attached to this topic:

TAPEGUARD HAS AN AUTOMATED NOTIFICATION SYSTEM THAT NOTIFIES ALL THE APPROPRIATE PERSONNEL INSTANTLY OF A TAPE REQUEST 24x7 VIA EMAIL AND SMS. FOR THE FASTEST TAPE RETURN USE TAPEGUARD REGARDLESS OF THE TIME.

Iron Mountain TapeGuard: `https://www.tapeguard.com/login <https://www.tapeguard.com/login>`_

The document attached to this page details how to use TapeGuard to request an emergency tape return. Specifically follow the notes on page 12.

In the event that you are unable use TapeGuard please contact 1800 IRONMTN (1800 476 668).

Leave the following information with an Iron Mountain Representative.

* First name and Surname

* Company name

* Telephone number (including area code.)

* Brief explanation of the problem

Strategic Data Directors are to be consulted if a disk is required to be retrieved.

Follow the steps contained here:

* :doc:`Recovering Offsite Backup <recovering-offsite-backup>`


Moving BackupPC
^^^^^^^^^^^^^^^^

When moving from one BackupPC server to another there are some things that you need to take into account.

* when moving the data it will take a long time

* remember to use the ``rsync -avH --numeric-ids``

* you need to copy the backuppc user's .ssh directory to the new server

* you need to make sure that any machine (like sd01) which uses /etc/security/access.conf has the new server entered into this file
